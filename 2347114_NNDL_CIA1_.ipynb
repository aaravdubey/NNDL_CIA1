{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llrp91p-18bC",
        "outputId": "b7ccebd0-803f-4276-e0ed-e6e1f7024542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLP Predictions for XOR gate:\n",
            "Input: [0 0] -> Output: 1\n",
            "Input: [0 1] -> Output: 1\n",
            "Input: [1 0] -> Output: 0\n",
            "Input: [1 1] -> Output: 0\n"
          ]
        }
      ],
      "source": [
        "# Q1. XOR gate Classification\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "\n",
        "def initialize_weights(input_size):\n",
        "    return np.zeros(input_size + 1)  # +1 is for bias\n",
        "\n",
        "def activation(summation):\n",
        "    return 1 if summation >= 0 else 0\n",
        "\n",
        "def predict(inputs, weights):\n",
        "    summation = np.dot(inputs, weights[1:]) + weights[0]  # Weights[0] is bias\n",
        "    return activation(summation)\n",
        "\n",
        "def train(X, y, weights, learning_rate=0.1, epochs=100):\n",
        "    for _ in range(epochs):\n",
        "        for inputs, label in zip(X, y):\n",
        "            prediction = predict(inputs, weights)\n",
        "            error = label - prediction\n",
        "            weights[1:] += learning_rate * error * inputs\n",
        "            weights[0] += learning_rate * error\n",
        "    return weights\n",
        "\n",
        "weights = initialize_weights(input_size=2)\n",
        "\n",
        "weights = train(X, y, weights, learning_rate=0.1, epochs=100)\n",
        "\n",
        "print(\"SLP Predictions for XOR gate:\")\n",
        "for inputs in X:\n",
        "    print(f\"Input: {inputs} -> Output: {predict(inputs, weights)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Layer Perceptron (MLP) for XOR\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(5,), activation='relu', solver='adam', max_iter=10000, learning_rate_init=0.01)\n",
        "\n",
        "mlp.fit(X, y)\n",
        "\n",
        "mlp_predictions = mlp.predict(X)\n",
        "\n",
        "print(\"\\nUpdated MLP Predictions for XOR gate:\")\n",
        "for inputs, prediction in zip(X, mlp_predictions):\n",
        "    print(f\"Input: {inputs} -> Output: {prediction}\")\n",
        "\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', s=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "zhIb6vMU2xnQ",
        "outputId": "30928a2e-abb0-4643-b9a1-42ef1c1797b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated MLP Predictions for XOR gate:\n",
            "Input: [0 0] -> Output: 0\n",
            "Input: [0 1] -> Output: 1\n",
            "Input: [1 0] -> Output: 1\n",
            "Input: [1 1] -> Output: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGdCAYAAADaPpOnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2s0lEQVR4nO3de3xU9YH38e/kNiHkJgnkIiGGi4Ag94LJtopLuijWR3a71ttWZBXX7vpaLa4Wdi0+aFvWO9WypV0fpbparfso3a0tLqI8VklRLil35BKTcJkACeRG7nOeP9IZcpkkM2HOzJwzn/frlVczJ+eEX6Yzydff95zzcxiGYQgAAMAiYsI9AAAAgEAQXgAAgKUQXgAAgKUQXgAAgKUQXgAAgKUQXgAAgKUQXgAAgKUQXgAAgKXEhXsAweZ2u3XixAmlpKTI4XCEezgAAMAPhmGovr5eubm5ionpf27FduHlxIkTysvLC/cwAADAIFRWVmrkyJH97mO78JKSkiJJ+n875io52XY/HgALONV8UpJU2vYX+rL+jCRp6/F879dbKpIlSVe0D1PFsbOSpLTDTZKkMQ7afESn1vZmvbL5R96/4/2x3V93T1WUnByn5JT4MI8GQLSpaj6uofGx2t66QCdaTyshOUFbKgsUmyTlNuerzFWt2EQp5ahDJ9SkafFZqjzkkuISNW6AqXIgGvhzyoftwgsAhEtV83FJ0tvVX5F0WqcaZ+lwTbUkqeXLZJWpWpPbM1Ve0bkt7YsmVapzxoXgAviP8AIAF8kTWra3LtDR+tOSpC2VBZIuBBdJvYKLRGgBBoPwAgAXoedsi+QJLhdqIqmzJipXtSYbaZ01kQguwGARXgBgkLoHF1ETASFCeAGAAFETAeFFeAGAAFATAeFHeAEAP1ETAZGB8AIAA+ivJvI12yJREwFmIrwAQD8CqYkkURMBIcA7CwD60HXGReqsiXoGl8ntmQQXIMR4dwFAPzzBpavc5vxe2yYbad7PCS6AuXiHAQAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAASyG8AAAAS4kL9wAAIBJVNR+XJB2tP+3ddrim2vt5mavz8/KKC9sqD7lCNDoguhFeAKAHT3B5u/orkqRTjbO8waXly2SVqVqT2zO9wSXtiyZVqknjYpjMBkKB8AIAf+IJLdtbF3hnXLZUFkiqVm5zvne2JeWoQ+W6EFwkEVyAECK8AIB6zrZ0DS7qFVwkabKR5q2JCC5AaBFeAEQ1T2iRqIkAqyC8AIha1ESANRFeAESl/moiz2yLRE0ERCLCC4Co4k9NJImaCIhgpr4TP/74Y914443Kzc2Vw+HQ+vXr+91/8+bNcjgcvT5cLu6dAODida2JPMFlS2WBDtd01kSe4JJy1NEtuEjMtgCRxNSZl8bGRk2dOlV/+7d/q7/6q7/y+7iDBw8qNTXV+3jEiBFmDA9AFOlZE/k6KVeiJgKswNTwcv311+v6668P+LgRI0YoPT09+AMCEHWoiQD7ich35rRp05STk6Ovf/3r+vTTT8M9HAAWFWhNNNlIoyYCLCCiTtjNycnR2rVrNWvWLLW0tOill17S3LlztXXrVs2YMcPnMS0tLWppafE+rqurC9VwAUSwnpdBd51t4aZzgLVFVHgZP368xo8f731cVFSkI0eO6Pnnn9drr73m85hVq1Zp5cqVoRoiAAvZ3rqg17bc5nzv55PbM1WuzhkXD4ILEPki/l06e/ZsHT58uM+vL1++XLW1td6PysrKEI4OAACEWkTNvPhSWlqqnJycPr/udDrldDpDOCIAABBOpoaXhoaGbrMmZWVlKi0t1bBhwzRq1CgtX75cx48f16uvvipJWr16tQoKCjRp0iQ1NzfrpZde0ocffqj/+Z//MXOYAADAQkwNL9u2bdO1117rfbx06VJJ0qJFi7Ru3TqdPHlSFRUV3q+3trbqoYce0vHjx5WUlKQpU6bogw8+6PY9AABAdDM1vMydO1eGYfT59XXr1nV7/Mgjj+iRRx4xc0gAAMDiIv6EXQAAgK4ILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwAAwFIILwBsp6r5uPfzo/WnJUmHa6q928pcnZ+XV1zYVnnIFaLRAbhYceEeAAAEkye4vF39FUmndapxlje4tHyZrDJ1fp5y1CFJmmykeYPLuBj+ew6wAsILAFvoOtvSGVzUK7hI0uT2TO+MS9oXTapUE6EFsBjCCwDL8wSX7a0LvDXRlsoCSdXKbc731kQpRx0qVzWzLYDFEV4AWBo1ERB9CC8ALKm/2RaJmgiwM97BACyn7+Ai5Tbne4NLylGHyis6a6K0L5okMdsC2AEzLwAsJdCayDPbIhFcALsgvACwhMHWRBKhBbAb3tEAIh41EYCumHkBENH8qYl8nZQrEVwAuyK8AIhI1EQA+sI7HEDEoSYC0B/e5QAi0vbWBd7PTzXOktQZXDwmt2d2/q+R5t1GcAGiA+90AABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKYQXAABgKXHhHgAQjRrq21R25LyazrcrNS1eYy5PVnw8/y2ByNPa3qJzjafV1t6ihPghGpY8QrEx/OlAePEKBEJo/546vbGuQv/9znE1Nbm920dkJejmO0bplr/JU1ZOYhhHCHQ6U39Su8tLdOD4DrW7W73bh8QP1aRRczQ5b45ShlwSxhEimhFegBAwDENrf3xEq588pJzsOH3v/nQtmDdUyUNjdOpMh375br3WrT2qV9Ye1eqfT9c180aEe8iIUoZhaOeXH+vTA+/J6RiiPGOMhitHsYpXm1rkaqtU6ZHfa2fZx5o/7XaNyZoc7iEjChFegBDwBJcVDw3Tvzw4THFxDu/Xxo+VvnbVEK36lwwt+scq/f1dO/Tvr89S0dWZYRwxolXpl7/Xpwfe02Uar9HGJMU4utaZKUpXpsYak7XPvV2/2/Gabph5lwpGTAzbeBGdTC3ZP/74Y914443Kzc2Vw+HQ+vXrBzxm8+bNmjFjhpxOp8aOHat169aZOUTAdAf21nmDy2P/lNEtuHSVlhqrt/89R3/+1SH6p78vVUtzR4hHimhX03BKnxz4jfI1XmMdV/YILhfEOeJ1peYoUzn6n9Jfqq291ed+gFlMDS+NjY2aOnWq1qxZ49f+ZWVluuGGG3TttdeqtLRUDz74oO655x69//77Zg4TMNXrr1QoNydO//LgsAH3jY936Mc/GK7q6jZt+I0rBKMDLthTUaIER6LG6IoB93U4HLpcU9Xa0ayDJ3eGYHTABabWRtdff72uv/56v/dfu3atCgoK9Oyzz0qSJk6cqE8++UTPP/+85s+fb9YwAdM01Lfpv985rmX3p/c549LT5WMSVHx1kt58tUI3/fWlJo8Q6NTe0aZ9x7bpUuMyxThi/TpmiGOoMo0c7S7fosl5c0weIXBBRF2bWVJSouLi4m7b5s+fr5KSkj6PaWlpUV1dXbcPIFKUHTmvpia3rp83NKDjFsxL0r7dvJYROrXnq9XW0aJM5QR0XKZydKb+pAzDPfDOQJBEVHhxuVzKysrqti0rK0t1dXVqamryecyqVauUlpbm/cjLywvFUAG/NDd1nreSPDSwt9rQoTFqbnbL7TbMGFZEq2o+7v38aP1pSdLhmmrvtjJXda9jKg9RsV2sto7O81ZiA5yQ9+zf7m4P+piAvkRUeBmM5cuXq7a21vtRWVkZ7iEBXimpnb/YT50J7OTb02c6lJwcq5gY/6omu/AEl7erv+INLlsqCyRJuc353uCSctSh8opqTTbSvMFlXIzlf52FlTN+iCSpVc0BHdeqZsU4YhQXE2/GsACfIupS6ezsbFVVVXXbVlVVpdTUVA0ZMsTnMU6nU06nMxTDAwI25vJkjchK0C/frdfXrvL9Gu7JMAy98W69Cr8WXZdKdw0uknSqcZZ3xqXly2SVqVqT2zNVXtG5Le2LJlWqc0aW4HLx0pIylOxMl6ulUhnK9usYwzBU5ajUyGFj5XBEV9BGeEXUO76wsFCbNm3qtm3jxo0qLCwM04iAixMfH6Nv/c0o/cd/1qu2zr/Zl49LmrTvYKvuWDzK5NFFhqrm46pqPq7trQu8wWVLZUG34CKpV3CROkMLwSU4YhwxujK/UFU6plajxa9j6lSjOuOsplxWZPLogO5Mfdc3NDSotLRUpaWlkjovhS4tLVVFRYWkzsrnzjvv9O5/33336ejRo3rkkUd04MAB/du//Zt+9atf6bvf/a6ZwwRM9a2/yZMhadE/Vqmtrf9zWE6dadc9D53SxEnJuuqrGaEZYBgNVBN5gkvXmqhrcEFwTRr5FcXGxmmvPpN7gBNwW40W7XNsV3rScOUPnxCiEQKdTH33b9u2TdOnT9f06dMlSUuXLtX06dO1YsUKSdLJkye9QUaSCgoK9N5772njxo2aOnWqnn32Wb300ktcJg1Ly8pO1OqfT9fvNp3Xjd8+oYOHe9/QyzAM/b8t5/VnNx5T/XmHXnx5pu2n4X3VRJ7g0vJlsspcnTVRytHO5yHtiybObzHZEGeybphxp846zmin4xM1GL2veDMMQ+eMM9ru2KyO2HZ9Y9Zdfd7MDjCLwzAMW13OUFdXp7S0NG3/oljJKZxAhshR8vszeug7paqubtO8q5N0w7wkDR0ao9NnOvTGu/Xad7BVEyal6Ccvz1DeqKRwD9c0ntCyvXXBgCflejDbElrHa47qdzv+Q01tDbrEMUKZRrbi/rS2UZXjmOqNc7pk6Ah9Y+YipQ8dHu7hwiZa25r1sw9WqLa2Vqmpqf3uS3gBQqiluUMbfuPSm69WaN/uOjU3u5WcHKvCr2XqjsWjdNVXM2w949JztkXqP7hwNVH4dLjbdcS1R7vKt+hU3TF1uNsVH5OgkRljNCX/z5SXOVYOZlwQRIQXwgsswu02ouZy6IGuJpJ8n5QrEVwigWG4CSswVSDhJaIulQaiTTQEl75roure925R76uJEBkILogkhBcApuk+2zLw+S3URAD8QXgBYIrB3nSO0AJgIIQXAEFFTQTAbPymABB0XYPLqcZZkjprIo/J7Z1LH0w20jTZSJNEcAHgP35bADCNJ7gAQDARXgAAQNgdGWBJiq4ILwAAIGwOud065Hbr0jFZfh9DeAEAAGFxyN0525I3Llv7HL3X0uoL4QUAAIScJ7jUXj5Eexy1GjXyEr+P5VJpAAAQMl1nW/Y4aiVJ9aMN7Wuu8ft7MPMCAABCoq/gIkn5I4b5/X2YeQEAAKbrWhPVqlb5ozK0J+6MJMl5WYNc58/4/b2YeQEAAKbxXE2UNy5btZcPkdQ529I1uEjS6EuYeQEAAGHWc7ZFulATFWRn6ERiuSSpKK9MrQ2tfn9fZl4AAEDQdQ0ukpQ/KsMbXJyXNehEYrnGDstQUV6ZJGnhsB1+f29mXgAAQND0dVLuHnWviTpDS2dwuTnjczXW+/9vMPMCAACCoue9W6TuNVH34CKNThmumzM+lySNSMzx+99h5gUAgCjmCRzB0rUm6npS7gk1aOywDI0Yuk2SvKFFkrISL1VDW5vf/wbhBQCAKNW14gmGnjVRz5Nyu9ZEUmdoGQzCCwAAUcjXlUDB0NfVRFJnTTQz4beSBh9cJMILAABRpWtN1LXiCQZ/aqKLCS0ehBcAAKLEQFcCXSyzaqKeCC8AAESB/m7PX5AdnJkXs2qinggvAADYWF81Uc+KJxjMqol6IrwAAGBT/dVEXSuescMufualM7SYUxP1RHgBAMCGBlrF2TPb0vXclItlVk3UE+EFAAAb8acmkrpXPKNThl/0vxuK0OJBeAEAwCb8rYk8sy1dZ0qCIRTBRSK8AAiiqubj/X69zFXda1vlIZdZwwGiSmA1UegqHjMQXgAEhSe4bG9doKP1pyVJh2s6w0puc743uKQcdahcnZ97gsu4GNaIBQbL31WcQ3UlUCgQXgBcNE9webv6K5I6g8uWygJJUsuXySrTheAiSZONNIILLC3YixlerJ7BRfJ9wzgrz7Z0RXgBMGhda6LO4CKdapzlnXFp+TJZkjS5PVPlFZ3b0r5oUqWaCC2wpK6hJViLGV6sPY7aPmui/lZxtjLCC4BB8VUTdc62VPdZE6V90SSJ2RZYU896JpiLGV4su9dEPRFeAASsZ03Uc7aFmgh24+tk2EjR9Rb/dq2JeiK8APAbNRGizUD3TIkUdq+JeiK8APBLoDURsy2wuoHumRIput7i3641UU+EFwADoiZCtPH3nimRwu41UU+EFwB9oiZCtAnk1vqRIhpqop4ILwB8oiZCtAn01vqRxO41UU+EFwC9UBMh2gzm1vqRIhpqop4ILwC8qIkQbQazAnPXeiZSRFNwkQgvAP6EmgjR5mJWYI62sBBpCC8AqIkQdaJpBWY7IrwAUay/2RaJmgjBE+kLGUbTrfXtgPACRKm+g4uoiRBUXeuZSBFNKzDbEeEFiEKB1kSe2RaJ4AL/9TwZNpIWMoymFZjtiPACRJHB1kQSoQWB8XUybKQsZrgn7gw1kcURXoAoQU2EUOnrZFhPYIgE1ETWRngBooA/NZGvk3Ilggv8N9A9UyJlMcMTieXURBZHeAFsjJoIoeLPPVMiaTFDaiJrC0l4WbNmjZ5++mm5XC5NnTpVL774ombPnu1z33Xr1mnx4sXdtjmdTjU3N4diqIBtUBMhVAK9Z0pkoCayMtPDy1tvvaWlS5dq7dq1mjNnjlavXq358+fr4MGDGjFihM9jUlNTdfDgQe9jh8Nh9jABW6EmQigM5tb6kbImkCe0SAQXKzI9vDz33HNasmSJdzZl7dq1eu+99/Tyyy9r2bJlPo9xOBzKzo6c+wEAVkFNhFC5mFvrRwpCi3WZGl5aW1u1fft2LV++3LstJiZGxcXFKikp6fO4hoYG5efny+12a8aMGfrRj36kSZMm+dy3paVFLS0t3sd1dXXB+wEAC6EmQqhwa32Em6nh5cyZM+ro6FBWVla37VlZWTpw4IDPY8aPH6+XX35ZU6ZMUW1trZ555hkVFRVp7969GjlyZK/9V61apZUrV5oyfsAqqIkQChezAjOhBcEUcVcbFRYWqrCw0Pu4qKhIEydO1M9+9jM98cQTvfZfvny5li5d6n1cV1envLy8kIwVCDdqIoQKKzAjkpgaXjIzMxUbG6uqqqpu26uqqvw+pyU+Pl7Tp0/X4cOHfX7d6XTK6XRe9FgBq+k52yJRE6G3YC6ISE2ESGFqeElISNDMmTO1adMmLVy4UJLkdru1adMm3X///X59j46ODu3evVsLFiwwcaSAtXQPLqImQi++ZkqCgRWYEQlMr42WLl2qRYsWadasWZo9e7ZWr16txsZG79VHd955py699FKtWrVKkvT444/rqquu0tixY3Xu3Dk9/fTTKi8v1z333GP2UIGI119N5Gu2RaImikY9T6iVgrOuUNc75VITIZxMDy+33HKLTp8+rRUrVsjlcmnatGnasGGD9yTeiooKxXT5pXr27FktWbJELpdLl1xyiWbOnKktW7boiiuuMHuoQEQLpCaSRE0UpboGF0lBX1fIV03ErfURag7DMIxwDyKY6urqlJaWpu1fFCs5JT7cwwGCYqCaSPJ9Uq5EcIkWfZ1QKwVvTSHPbAs1EczQUN+mmZd/oNraWqWmpva7b8RdbQTgAmoi+MNXTdQ1uHhCRzBQEyESEF6ACEVNBH/0VRNJFyqescOCM/PCCsyIFIQXIAIN9moiQkv0CPS+K8FCTYRIQHgBIgg1Efzhb03U9b4rwUBNhEhBeAEiBDUR/OFvTeSr4gkGggsiAeEFCDNPaJGoidC3wdREVDywK8ILEEbURPDHYGoiKh7YGeEFCBNqInsL5ppCUuA1EaEFdkZ4AUKMmsj+ulY8wUBNBHRHeAFCiJrI/nxVPMFATQRcQHgBQqRnTeRrtkWiJrIqXyfUBmMxREnUREAPhBfAZP7URFLvtYmoiayjvyuBgoGaCOiO8AKYKNCaiNkW6+lZE3U9oTYYCyKeSCzvtYozNRGiHeEFMAk1kb0NNNviqXiCgZoI6I7wAgQZNZH99RVcpO4VTzAWROwMLaziDHRFeAGCiJrI/vqriXqfUBucBREJLkB3hBcgSKiJ7M2fmkjqXvEEY0FEQgvQG+EFuEjURPbnb03kuRKo60xJMBBcgO4IL8BFoCayv8Bqou6rOBM6AHMQXoBBoiayt8HURFwJBIQG4QUIUH+zLRI1kR1cTE1EcAHMR3gBAtB3cOm9EjQ1kTVREwGRj/AC+ImayN6oiQDrILwAA6Amsj9fK0FTEwGRi/AC9IOayP66BhdJ1ESABRBegD74UxP5mm2RCC5W4G9NxCrOQOQhvAA9DLYmkggtVhFYTcTt+YFIQ3gBuqAmsj9qIsD6CC/An1AT2Vt/NZGvk3IlaiIgUhFeEPWoieyPmgiwF8ILoho1kf0NtiYitACRi/CCqEVNZG/URIB9EV4QdaiJ7I+aCLA3wguiSs/ZFomayE48oUWiJgLsjPCCqNE9uIiayGaoiYDoQXiB7fVXE/mabZGoiayGmgiILoQX2FogNZHEStBWQ00ERCfCC2yLmsjeqImA6EV4ge1QE9lfz5rI12yLRE0E2BXhBbZCTWRv/tREkqiJAJsjvMA2BlsTEVqsIdCaiNkWwL4IL7A8aiL7oyYC0BXhBZZGTWRv1EQAfCG8wJI8oUWiJrIraiIAfSG8wHKoieyPmghAfwgvsBRqInujJgLgD8ILLIGayP6oiQD4i/CCiEdNZH/URAACQXhBROtZE/mabZGoiazKV03kmW2RqIkA+EZ4QUTypyaSZMmaqKbhlPZW/kGnzh1XW0eLnPFJysscp0kjv6IhzuRwDy9k+qqJJF8rQVMThcOXRxv11muV2vPHczrf2K7k1Hhd9WcZ+uvb8zR8hDPcw0MUcxiGYYR7EMFUV1entLQ0bf+iWMkp8eEeDgah75rI90m5kjVqotrzNfpw99s6VnNECY5EDTOGK1ZxalWLqlUlOaQJl87Q1VfcpPjYhHAP11RdayLJ90m5EjVRuJw83qTv/9Nu/X5ztTIuidXX5w5RytAYnanp0IYPz6utXfrGX+bo+z+apORk/hsYwdFQ36aZl3+g2tpapaam9rsvrzpEFLvWRDUNp/TOH34qtUuTNFtZxqWKccR6v95qtOiE8aUOHtup6jqXFs65Vwlx9vsv2/5OypWoiSJBxZeN+pu/3KqE2A698uMsfet/JSsx8cJ76+y5Dv3irTr972dcOnSgXr/4zzlKSeU/FBFazLwgIgy2JpIiO7RIUmt7s974/XMyWgzNML6mBEdin/vWGTXaod8rb8Q4fWPmXaEbZAgEVhMx2xIOTec7tPDrnyje0a6P/u+lysnq+79vd+1r0bV/dUxXTr9E//7GV+RwOPrcF/BHIDMvIfmtv2bNGl122WVKTEzUnDlz9Nlnn/W7/9tvv60JEyYoMTFRV155pX7729+GYpgIk641kSe4bKks0OGazquJPMEl5ahD5RXVmmykWSa4SNKB4zvU0FyrKUZhv8FFklIdwzRB01V2ap/O1J8M0QjN17Um2uPovJrIE1yclzXoRGK5xg7L8AaXmzM+J7iEwXu/PqHysvN69+WcfoOLJE25wql/fzZLv99crd2ltSEaIdDJ9N/8b731lpYuXarHHntMO3bs0NSpUzV//nydOnXK5/5btmzRbbfdprvvvls7d+7UwoULtXDhQu3Zs8fsoSIMutZER+s7ayLP+S0tXyZb/qZzhmFoV/kWZSpXSQ7/TsYdoZFyOoZoT8UfTB6d+Q653TrkditvXHb3q4n8vOkcwSW03vxFheZfm6SJl/t3ztVN1w3VqJHx+uUvKkweGdCd6b/9n3vuOS1ZskSLFy/WFVdcobVr1yopKUkvv/yyz/1//OMf67rrrtPDDz+siRMn6oknntCMGTP0k5/8xOyhIoSqmo/3OL+l75rIE1zSvmhS5SGXxsXEWCK4SNLZxtM623hKl+oyv4+JccQoxxilQyf+aN7AQmCgmsgTXIryyjRi6DaNThnO+S1hdLyySbv/WKe/va3/6fquYmMdWnxrijb8t31mCWENpp6w29raqu3bt2v58uXebTExMSouLlZJSYnPY0pKSrR06dJu2+bPn6/169f73L+lpUUtLS3ex3V1dRc/cJgq0JvOWW22pavm1kZJ0hANDei4RA1Vc/t5GYZbDoe1fmbJv5vO+ZptkQgu4VJT3SpJGp0f2LmCBaPidf68W81NHUocEjvwAUAQmBpezpw5o46ODmVlZXXbnpWVpQMHDvg8xuVy+dzf5XL53H/VqlVauXJlcAYM09n1aqK+xMR0/jI3FNh58YbcinHESLLWSZBcTWRd8fGdr7W29sCOa2vvfG3HxVvrtQprs95fgx6WL1+u2tpa70dlZWW4hwQffNVEnpNyJfvURD2lDrlEDjl07k9/vP1VqxqlDcmw1BUc1ETWlnPpEMXHO7Tls6aAjivZ1qyReYmKi7PmexTWZOrMS2ZmpmJjY1VVVdVte1VVlbKzs30ek52dHdD+TqdTTqf97odhJ4HcdM7qNVFPSc4UXTZioo6dLtOlxmi/wkir0axTOqaiUQtCMMLgoCayvrT0eP3FDVn66as1+scl6YqJGfi1evZch375Tr3+7oGxIRghcIGpfxkSEhI0c+ZMbdq0ybvN7XZr06ZNKiws9HlMYWFht/0laePGjX3uj8hm96uJ/DFlVJEajHM6pWN+7X9U++VwxGjipbNMHtnF42oie7ntznwdPtqq1/6z3q/9V71Qo7Z26a9vzzN5ZEB3pt9hd+nSpVq0aJFmzZql2bNna/Xq1WpsbNTixYslSXfeeacuvfRSrVq1SpL0wAMP6JprrtGzzz6rG264QW+++aa2bdumn//852YPFUHU30m5krXXJgpUXuY4jcueor2ubYoxYjXcketzP8MwdFT7dExHdPXEm5SYkBTikQam52yLxNpEVjfrqkv0l9/K1X0Pn1RykkPf/EaKz/0Mw9BTPzmrZ396Tg9/fzzrHCHkTA8vt9xyi06fPq0VK1bI5XJp2rRp2rBhg/ek3IqKCsV0+WNVVFSkN954Q48++qj++Z//WePGjdP69es1efJks4eKIInmmsgXh8Oh4im3qMP9hv54aosyjRyN1GhlKFsOh0MdRrtcqtRxx1HVGWd11eXXaWr+n4V72P0aaG0iaiJrcjgcevzpK9XS4ta3lrh03Z/X6Tt3pen6Px+q2FiHmpvd+tV/Neinv6jVZzua9fffHaO7v1MQ7mEjCrE8AILK33u39LzFv2TP4NKV23Br/7HP9ccvP1V1g0sOORTriFO70SZJys8cr2kFV2tU5rgwj7Rv/Z2UK6nbSbkenJRrPW63oV//53H9x/8p155ddYqNlYYmxai+wS3DkL56TYbuXFKga+YND/dQYSOBLA9AeEFQ9DfbIll7baJgMwxDVecqdLruhNo6WpQQP0R5w8YqbWhGuIfWr56zLRJrE0WDXaXntOePtTrf2KGUlDjNLspQwZjA7lsE+INVpRFS1ESBcTgcyr4kX9mX5Id7KH6jJopeU6ala8q09HAPA+iG8IKL4s9N53ydlCtFZ3Cxmv5uOufrpFyJmgiA+QgvGJTBXk0kEVqsIrCriaiJAIQO4QUBoyayv8HWRIQWAKFAeEFAqInsjZoIgBUQXuAXaiL7oyYCYBWEFwyo52yLRE1kJ57QIlETAbAGwgv6NdBN56iJrI2aCIAVEV7gk781kWe2RaImshpqIgBWRXhBL4HURJI9V4K2M2oiAFZHeEE31ET2Rk0EwA4IL5DUf03k66RciZrIanrWRL5mWyRqIgCRj/ACaiKb86cmkkRNBMAyCC9RbrA1EaHFGqiJANgR4SVKURPZHzURALsivEQhaiJ7oyYCYHeElyhDTWRvgdZEzLYAsCLCS5SgJooenuCSPypDknoFl7HDMkRwAWBlhJcoQE0Ej87g0h3BBYDVEF5szBNaJGoiAIB9EF5sipoIAGBXhBcb6lkT+ZptkaiJAADWRHixEX9qIknURAAASyO82AQ1EQAgWhBebICaCAAQTQgvFkZNBACIRoQXiwq0JmK2BQBgF4QXC6ImAgBEM8KLhVATAQBAeLEMaiIAADoRXiyAmggD8awmLcm7mrQk7Yk7I0neRRklacTQbZLkXZQRAKyG8BLBfNVEntkWiZoInTzBxbOatCTVjzZ6rSZdlFcmVpMGYAeElwjVd03UeyVoaqLo5QkutZcPUa1qlT8qwzvb4rysQSfUIMkTXERwAWALhJcIRE2EgXStiWovHyLpwmyL1BlcJGnssAxvTXRzxueSCC0ArI/wEkH6OylXoiZCp75qIknURACiAuElQlATwR/URABAeIkI/tREvmZbJIJLtOjvpFyJmghAdCG8hNFgayKJ0BJNqIkAoDvCS5hQE8Ef/tREvmZbJIILAPsivIQBNREGQk0EAH0jvIQQNRH8QU0EAP0jvIQINRH8QU0EAAMjvIQANREGQk0EAP4jvJiImgj+oCYCgMAQXkzSc7ZFoiZCb9REABA4wosJugcXUROhF2oiABg8wksQURPBHz1nWyRqIgAIBOElSKiJ4I+uwUUSNREADALhJQioiTAQf2siz2yLRE0EAH0hvFyE/moiX7MtEjVRNAqsJmIlaAAYCOFlkAKpiSRRE0UpaiIACD5T/4rW1NTojjvuUGpqqtLT03X33XeroaGh32Pmzp0rh8PR7eO+++4zc5gB81UTeYJLy5fJKnN11kSe4JL2RZMqD7k0LiaG4BIlDrndOuR2K29ctje41I82tCfujAqyM7rVRL6uJiK4AEDfTJ15ueOOO3Ty5Elt3LhRbW1tWrx4se6991698cYb/R63ZMkSPf74497HSUlJZg7Tb9RE8Ac1EQCYy7Twsn//fm3YsEGff/65Zs2aJUl68cUXtWDBAj3zzDPKzc3t89ikpCRlZ2ebNbRBoSaCPwZbExFaAMB/pv1VLSkpUXp6uje4SFJxcbFiYmK0devWfo99/fXXlZmZqcmTJ2v58uU6f/68WcP0CzURBnKxNREAwH+mzby4XC6NGDGi+z8WF6dhw4bJ5XL1edztt9+u/Px85ebmateuXfre976ngwcP6p133vG5f0tLi1paWryP6+rqgvMDiJoI/qEmAoDQCji8LFu2TE8++WS/++zfv3/QA7r33nu9n1955ZXKycnRvHnzdOTIEY0ZM6bX/qtWrdLKlSsH/e/1hZoIA/GEFomaCABCKeDw8tBDD+muu+7qd5/Ro0crOztbp06d6ra9vb1dNTU1AZ3PMmfOHEnS4cOHfYaX5cuXa+nSpd7HdXV1ysvL8/v79+QJLVLgN50jtESP/m465+sW/xLBBQCCJeDwMnz4cA0fPnzA/QoLC3Xu3Dlt375dM2fOlCR9+OGHcrvd3kDij9LSUklSTk6Oz687nU45nU6/v19/qIngD2oiAAgv0855mThxoq677jotWbJEa9euVVtbm+6//37deuut3iuNjh8/rnnz5unVV1/V7NmzdeTIEb3xxhtasGCBMjIytGvXLn33u9/V1VdfrSlTppg1VEm9ayJfsy0SNVE0oyYCgMhg6n1eXn/9dd1///2aN2+eYmJi9M1vflMvvPCC9+ttbW06ePCg92qihIQEffDBB1q9erUaGxuVl5enb37zm3r00UdNG6M/NZHUeyVoaqLoQk0EAJHDYRiGEe5BBFNdXZ3S0tK0/YtiJafE97tv3zWR75NyJWqiaDTQvVs8qIkAYPAa6ts08/IPVFtbq9TU1H73jdq1jaiJMBB/aiJJ1EQAEGJRF16oieAPaiIAiFxRFV4CvZqI2Zbo1PNqIl8n5UrURAAQLlETXqiJMBBqIgCwBtuHF2oi+CPQmojZFgAIH1uHF2oi+IOaCACsxbbh5VTzSQ2Nj6UmQp+oiQDAmmwbXqQLNZFntkWiJkInaiIAsC7b/rVeXzNDUvebznmCS8pRh8orOmsibjoXfbrWRHscnTWRZ20i52UNrE0EABHOtjMvp89PV/nZzmUHqIkgURMBgF3YNrwcPVuj2KREaiJIoiYCADuxbXjJbh6lY6c6Z164mii6cTURANiLbcNL+akaTY0b2Wu2RSK4RIv+ZlskaiIAsCrbhpcr2oep/MSF4CIRWqJJX8FFEjURAFicbcNLxbGzmhafRU0UhfypiXzNtkgEFwCwAtuGl7TDTaqMI7hEE2oiAIgOtg0vEqElmlATAUD0sG14GeMguEQLaiIAiC62DS+wP2oiAIhOhBdYEjURAEQvwgssh5oIAKIb4QWWQU0EAJAIL7CInrMtEjURAEQrwgsiXtfgIvVeCZqaCACiC+EFEYuaCADgC+EFEYmaCADQF8ILIg41EQCgP4QXRIz+aiJfsy0SNREARCPCCyJCYDWRqIkAIIoRXhB2g62JCC0AEJ0ILwgbaiIAwGAQXhAW1EQAgMEivCDkqIkAABeD8IKQoSYCAAQD4QUhQU0EAAgWwgtM5QktEjURACA4CC8wDTURAMAMhBeYor+ayDPbIlETAQACR3hBUPlTE0msBA0AGDzCC4KGmggAEAqEFwRFz5rI10m5EjURAODiEV5wUaiJAAChRnjBoAVaEzHbAgAIBsILBoWaCAAQLoQXBKzrjEvP4FKQndHrpnOe4EJoAQAEQ0y4BwBr8lRF+aMyvNsKsjN67Tc6ZXgohwUAiAKEFwAAYCmEFwAAYCmEFwAAYCmEFwAAYCmEFwAAYCmEFwAAYCmEFwAAYCmmhZcf/vCHKioqUlJSktLT0/06xjAMrVixQjk5ORoyZIiKi4t16NAhs4YIAAAsyLTw0traqptvvlnf+c53/D7mqaee0gsvvKC1a9dq69atGjp0qObPn6/m5mazhgkAACzGtOUBVq5cKUlat26dX/sbhqHVq1fr0Ucf1U033SRJevXVV5WVlaX169fr1ltvNWuoAADAQiJmbaOysjK5XC4VFxd7t6WlpWnOnDkqKSnpM7y0tLSopaXF+7i2tnN149Z2ZmvM0m641drapHZHs9qaz0uSOuKa1Xa+qfNzd7PanE1qNVrV7Oj8/6YxvkMNbW1hGzMAILI1NLRL6pzMGEjEhBeXyyVJysrK6rY9KyvL+zVfVq1a5Z3l6eqVzT8K7gDR3abO//m8y6b9XT4v9XnQXrNGAwCwifr6eqWlpfW7T0DhZdmyZXryySf73Wf//v2aMGFCIN/2oixfvlxLly71Pj537pzy8/NVUVEx4A8P/9XV1SkvL0+VlZVKTU0N93BsgefUHDyvwcdzag6e1+4Mw1B9fb1yc3MH3Deg8PLQQw/prrvu6nef0aNHB/ItvbKzsyVJVVVVysnJ8W6vqqrStGnT+jzO6XTK6XT22p6WlsaLwQSpqak8r0HGc2oOntfg4zk1B8/rBf5OOgQUXoYPH67hw4cPakADKSgoUHZ2tjZt2uQNK3V1ddq6dWtAVywBAAB7M+1S6YqKCpWWlqqiokIdHR0qLS1VaWmpGhoavPtMmDBB7777riTJ4XDowQcf1A9+8AP913/9l3bv3q0777xTubm5WrhwoVnDBAAAFmPaCbsrVqzQL37xC+/j6dOnS5I++ugjzZ07V5J08OBB79VBkvTII4+osbFR9957r86dO6evfvWr2rBhgxITE/3+d51Opx577DGfVRIGj+c1+HhOzcHzGnw8p+bgeR08h+HPNUkAAAARgrWNAACApRBeAACApRBeAACApRBeAACApdgivPzwhz9UUVGRkpKSlJ6e7tcxhmFoxYoVysnJ0ZAhQ1RcXKxDhw6ZO1CLqamp0R133KHU1FSlp6fr7rvv7napuy9z586Vw+Ho9nHfffeFaMSRZ82aNbrsssuUmJioOXPm6LPPPut3/7ffflsTJkxQYmKirrzySv32t78N0UitJZDndd26db1ek4FcwRgNPv74Y914443Kzc2Vw+HQ+vXrBzxm8+bNmjFjhpxOp8aOHev3IrzRItDndPPmzb1epw6Ho9/lcaKZLcJLa2urbr755oBuZvfUU0/phRde0Nq1a7V161YNHTpU8+fPV3MzCzp63HHHHdq7d682btyo3/zmN/r444917733DnjckiVLdPLkSe/HU089FYLRRp633npLS5cu1WOPPaYdO3Zo6tSpmj9/vk6dOuVz/y1btui2227T3XffrZ07d2rhwoVauHCh9uzZE+KRR7ZAn1ep8w6mXV+T5eXlIRxx5GtsbNTUqVO1Zs0av/YvKyvTDTfcoGuvvValpaV68MEHdc899+j99983eaTWEehz6nHw4MFur9URI0aYNEKLM2zklVdeMdLS0gbcz+12G9nZ2cbTTz/t3Xbu3DnD6XQav/zlL00coXXs27fPkGR8/vnn3m2/+93vDIfDYRw/frzP46655hrjgQceCMEII9/s2bONf/iHf/A+7ujoMHJzc41Vq1b53P9b3/qWccMNN3TbNmfOHOPv/u7vTB2n1QT6vPr7ewGdJBnvvvtuv/s88sgjxqRJk7ptu+WWW4z58+ebODLr8uc5/eijjwxJxtmzZ0MyJquzxcxLoMrKyuRyuVRcXOzdlpaWpjlz5qikpCSMI4scJSUlSk9P16xZs7zbiouLFRMTo61bt/Z77Ouvv67MzExNnjxZy5cv1/nz580ebsRpbW3V9u3bu73GYmJiVFxc3OdrrKSkpNv+kjR//nxek10M5nmVpIaGBuXn5ysvL0833XST9u5lhfOLwWvVPNOmTVNOTo6+/vWv69NPPw33cCKWaXfYjWSeDjErK6vb9qysLPrFP3G5XL2mK+Pi4jRs2LB+n6Pbb79d+fn5ys3N1a5du/S9731PBw8e1DvvvGP2kCPKmTNn1NHR4fM1duDAAZ/HuFwuXpMDGMzzOn78eL388suaMmWKamtr9cwzz6ioqEh79+7VyJEjQzFs2+nrtVpXV6empiYNGTIkTCOzrpycHK1du1azZs1SS0uLXnrpJc2dO1dbt27VjBkzwj28iBOx4WXZsmV68skn+91n//79mjBhQohGZA/+Pq+D1fWcmCuvvFI5OTmaN2+ejhw5ojFjxgz6+wKDVVhYqMLCQu/joqIiTZw4UT/72c/0xBNPhHFkwAXjx4/X+PHjvY+Liop05MgRPf/883rttdfCOLLIFLHh5aGHHtJdd93V7z6jR48e1PfOzs6WJFVVVSknJ8e7vaqqyruitV35+7xmZ2f3OgGyvb1dNTU13ufPH3PmzJEkHT58OKrCS2ZmpmJjY1VVVdVte1VVVZ/PX3Z2dkD7R6PBPK89xcfHa/r06Tp8+LAZQ4wKfb1WU1NTmXUJotmzZ+uTTz4J9zAiUsSGl+HDh2v48OGmfO+CggJlZ2dr06ZN3rBSV1enrVu3BnTFkhX5+7wWFhbq3Llz2r59u2bOnClJ+vDDD+V2u72BxB+lpaWS1C0kRoOEhATNnDlTmzZt8q6K7na7tWnTJt1///0+jyksLNSmTZv04IMPerdt3Lix26xBtBvM89pTR0eHdu/erQULFpg4UnsrLCzsdRk/r9XgKy0tjbrfnX4L9xnDwVBeXm7s3LnTWLlypZGcnGzs3LnT2Llzp1FfX+/dZ/z48cY777zjffyv//qvRnp6uvHrX//a2LVrl3HTTTcZBQUFRlNTUzh+hIh03XXXGdOnTze2bt1qfPLJJ8a4ceOM2267zfv1Y8eOGePHjze2bt1qGIZhHD582Hj88ceNbdu2GWVlZcavf/1rY/To0cbVV18drh8hrN58803D6XQa69atM/bt22fce++9Rnp6uuFyuQzDMIxvf/vbxrJly7z7f/rpp0ZcXJzxzDPPGPv37zcee+wxIz4+3ti9e3e4foSIFOjzunLlSuP99983jhw5Ymzfvt249dZbjcTERGPv3r3h+hEiTn19vff3piTjueeeM3bu3GmUl5cbhmEYy5YtM7797W979z969KiRlJRkPPzww8b+/fuNNWvWGLGxscaGDRvC9SNEnECf0+eff95Yv369cejQIWP37t3GAw88YMTExBgffPBBuH6EiGaL8LJo0SJDUq+Pjz76yLuPJOOVV17xPna73cb3v/99Iysry3A6nca8efOMgwcPhn7wEay6utq47bbbjOTkZCM1NdVYvHhxt0BYVlbW7XmuqKgwrr76amPYsGGG0+k0xo4dazz88MNGbW1tmH6C8HvxxReNUaNGGQkJCcbs2bONP/zhD96vXXPNNcaiRYu67f+rX/3KuPzyy42EhARj0qRJxnvvvRfiEVtDIM/rgw8+6N03KyvLWLBggbFjx44wjDpyeS7T7fnheR4XLVpkXHPNNb2OmTZtmpGQkGCMHj262+9XBP6cPvnkk8aYMWOMxMREY9iwYcbcuXONDz/8MDyDtwCHYRhGiCd7AAAABi0q7/MCAACsi/ACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAshfACAAAs5f8DdiHVS6HcHyoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/Tweets - Tweets.csv')\n",
        "\n",
        "data_filtered = data[data['airline_sentiment'].isin(['positive', 'negative'])]\n",
        "\n",
        "texts = data_filtered['text'].values\n",
        "labels = data_filtered['airline_sentiment'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)  # positive = 1 & negative = 0\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
        "X = vectorizer.fit_transform(texts).toarray()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "UET46soV5bn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.where(x > 0, 1, 0)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.tanh(x)**2\n",
        "\n",
        "def initialize_weights(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(input_size, hidden_size) * 0.01  # Input to hidden layer weights\n",
        "    b1 = np.zeros((1, hidden_size))  # Hidden layer bias\n",
        "    W2 = np.random.randn(hidden_size, output_size) * 0.01  # Hidden to output layer weights\n",
        "    b2 = np.zeros((1, output_size))  # Output layer bias\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def forward_propagation(X, W1, b1, W2, b2, activation_function):\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    if activation_function == 'sigmoid':\n",
        "        A1 = sigmoid(Z1)\n",
        "    elif activation_function == 'relu':\n",
        "        A1 = relu(Z1)\n",
        "    elif activation_function == 'tanh':\n",
        "        A1 = tanh(Z1)\n",
        "\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def backward_propagation(X, y, W1, b1, W2, b2, Z1, A1, A2, activation_function):\n",
        "    m = X.shape[0]\n",
        "    dZ2 = A2 - y.reshape(-1, 1)\n",
        "    dW2 = np.dot(A1.T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "\n",
        "    if activation_function == 'sigmoid':\n",
        "        dA1 = np.dot(dZ2, W2.T) * sigmoid_derivative(Z1)\n",
        "    elif activation_function == 'relu':\n",
        "        dA1 = np.dot(dZ2, W2.T) * relu_derivative(Z1)\n",
        "    elif activation_function == 'tanh':\n",
        "        dA1 = np.dot(dZ2, W2.T) * tanh_derivative(Z1)\n",
        "\n",
        "    dW1 = np.dot(X.T, dA1) / m\n",
        "    db1 = np.sum(dA1, axis=0, keepdims=True) / m\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def train_neural_network(X_train, y_train, hidden_size, epochs, learning_rate, activation_function):\n",
        "    input_size = X_train.shape[1]\n",
        "    output_size = 1  # Binary classification\n",
        "    W1, b1, W2, b2 = initialize_weights(input_size, hidden_size, output_size)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        Z1, A1, Z2, A2 = forward_propagation(X_train, W1, b1, W2, b2, activation_function)\n",
        "\n",
        "        m = y_train.shape[0]\n",
        "        loss = -np.mean(y_train * np.log(A2) + (1 - y_train) * np.log(1 - A2))\n",
        "        losses.append(loss)\n",
        "\n",
        "        dW1, db1, dW2, db2 = backward_propagation(X_train, y_train, W1, b1, W2, b2, Z1, A1, A2, activation_function)\n",
        "\n",
        "        W1 -= learning_rate * dW1\n",
        "        b1 -= learning_rate * db1\n",
        "        W2 -= learning_rate * dW2\n",
        "        b2 -= learning_rate * db2\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "    return W1, b1, W2, b2, losses\n",
        "\n",
        "def predict(X, W1, b1, W2, b2, activation_function):\n",
        "    _, _, _, A2 = forward_propagation(X, W1, b1, W2, b2, activation_function)\n",
        "    return (A2 > 0.5).astype(int)\n",
        "\n",
        "def evaluate_model(X_train, X_test, y_train, y_test, activation_functions):\n",
        "    results = {}\n",
        "\n",
        "    for activation_function in activation_functions:\n",
        "        print(f\"Training with {activation_function} activation function...\")\n",
        "        W1, b1, W2, b2, losses = train_neural_network(X_train, y_train, hidden_size=10, epochs=1000, learning_rate=0.01, activation_function=activation_function)\n",
        "\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'Loss over Epochs ({activation_function})')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "\n",
        "        y_pred = predict(X_test, W1, b1, W2, b2, activation_function)\n",
        "\n",
        "        accuracy = np.mean(y_pred.flatten() == y_test) * 100\n",
        "        print(f\"Test Accuracy with {activation_function} activation: {accuracy:.2f}%\\n\")\n",
        "        results[activation_function] = accuracy\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "lJF3Wk7J6QN_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
        "\n",
        "results = evaluate_model(X_train, X_test, y_train, y_test, activation_functions)\n",
        "\n",
        "for activation_function, accuracy in results.items():\n",
        "    print(f\"Final Test Accuracy using {activation_function} activation: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "8Bgem2NVJuDZ",
        "outputId": "dc5a1ff4-e625-4228-fd70-f7278aa7c1e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with relu activation function...\n",
            "Epoch 0, Loss: 0.6931371497758132\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-bc81f568b487>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate models using different activation functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print final results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ea6849c4974b>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(X_train, X_test, y_train, y_test, activation_functions)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mactivation_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivation_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training with {activation_function} activation function...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Plot the loss curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ea6849c4974b>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(X_train, y_train, hidden_size, epochs, learning_rate, activation_function)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mdW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Update the weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ea6849c4974b>\u001b[0m in \u001b[0;36mbackward_propagation\u001b[0;34m(X, y, W1, b1, W2, b2, Z1, A1, A2, activation_function)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradient for output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}